import pandas as pd
import numpy as np
import pickle

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier



malware_dataset = pd.read_csv("/home/ubuntu/Desktop/P5-Hardwall/MalwareClassifier/MalwareData.csv", sep="|")

# Separate benign and malicious samples
benign_samples = malware_dataset[0:41323].drop(["legitimate"], axis=1)
malicious_samples = malware_dataset[41323::].drop(["legitimate"], axis=1)

print("Shape benign: %s samples, %s features" % (benign_samples.shape[0], benign_samples.shape[1]))
print("Shape malicious: %s samples, %s features" % (malicious_samples.shape[0], malicious_samples.shape[1]))

print(malware_dataset.columns)
print(malware_dataset.head(5))


print(benign_samples.take([1]))
print(malicious_samples.take([1]))

# Tree Classifier

raw_features = malware_dataset.drop(['Name', 'md5', 'legitimate'], axis=1).values
labels = malware_dataset['legitimate'].values


extra_trees_classifier = ExtraTreesClassifier().fit(raw_features, labels)
feature_selector = SelectFromModel(extra_trees_classifier, prefit=True)

# Transform the input data using the selected features
selected_features_data = feature_selector.transform(raw_features)

# Print the shapes of the original and transformed data
print(raw_features.shape, selected_features_data.shape)

# Save the selected features to a file
selected_features = malware_dataset.drop(['Name', 'md5', 'legitimate'], axis=1).columns[feature_selector.get_support()]
selected_features_path = 'selected_features.pkl'
print(f"Selected features: {selected_features.tolist()}")
with open(selected_features_path, 'wb') as file:
    pickle.dump(selected_features, file)
print(f"Selected features saved to {selected_features_path}")


# Get the number of features in the transformed data
num_features = selected_features_data.shape[1]

# Calculate feature importances using ExtraTreesClassifier
feature_importances = extra_trees_classifier.feature_importances_

# Get the indices of the features sorted by importance in descending order
sorted_feature_indices = np.argsort(feature_importances)[::-1]

# Print the feature ranking
for f in range(num_features):
    print("%d" % (f+1), malware_dataset.columns[2 + sorted_feature_indices[f]], feature_importances[sorted_feature_indices[f]])

# Split the data into training and testing sets
train_features, test_features, train_labels, test_labels = train_test_split(selected_features_data, labels, test_size=0.2)

# Train Random Forest Classifier
random_forest_classifier = RandomForestClassifier(n_estimators=50)
random_forest_classifier.fit(train_features, train_labels)

print("Random Forest Classifier score: ", random_forest_classifier.score(test_features, test_labels) * 100)

# Predict the labels for the test data
predicted_labels = random_forest_classifier.predict(test_features)

# Compute the confusion matrix
confusion_matrix_result = confusion_matrix(test_labels, predicted_labels)
print(confusion_matrix_result.shape)

# Save the Random Forest model
with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(random_forest_classifier, file)

# Train Gradient Boosting Classifier
gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=50)
gradient_boosting_classifier.fit(train_features, train_labels)

print("The score of the Gradient Boosting Classifier is: ", gradient_boosting_classifier.score(test_features, test_labels) * 100)







